{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "md_intro_imports",
   "metadata": {},
   "source": [
    "# Import Dependencies\n",
    "- Import common libraries for data analysis, visualization, and modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a12fcdf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, StratifiedKFold, cross_validate\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, classification_report\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.tree import plot_tree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7deac91",
   "metadata": {},
   "source": [
    "# Data Loading and Preview\n",
    "- Load `sf-crime/train.csv`\n",
    "- Preview the first rows and summarize missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c3adcdaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First few rows:\n",
      "                 Dates        Category                      Descript  \\\n",
      "0  2015-05-13 23:53:00        WARRANTS                WARRANT ARREST   \n",
      "1  2015-05-13 23:53:00  OTHER OFFENSES      TRAFFIC VIOLATION ARREST   \n",
      "2  2015-05-13 23:33:00  OTHER OFFENSES      TRAFFIC VIOLATION ARREST   \n",
      "3  2015-05-13 23:30:00   LARCENY/THEFT  GRAND THEFT FROM LOCKED AUTO   \n",
      "4  2015-05-13 23:30:00   LARCENY/THEFT  GRAND THEFT FROM LOCKED AUTO   \n",
      "\n",
      "   DayOfWeek PdDistrict      Resolution                    Address  \\\n",
      "0  Wednesday   NORTHERN  ARREST, BOOKED         OAK ST / LAGUNA ST   \n",
      "1  Wednesday   NORTHERN  ARREST, BOOKED         OAK ST / LAGUNA ST   \n",
      "2  Wednesday   NORTHERN  ARREST, BOOKED  VANNESS AV / GREENWICH ST   \n",
      "3  Wednesday   NORTHERN            NONE   1500 Block of LOMBARD ST   \n",
      "4  Wednesday       PARK            NONE  100 Block of BRODERICK ST   \n",
      "\n",
      "            X          Y  \n",
      "0 -122.425892  37.774599  \n",
      "1 -122.425892  37.774599  \n",
      "2 -122.424363  37.800414  \n",
      "3 -122.426995  37.800873  \n",
      "4 -122.438738  37.771541  \n",
      "Missing values:\n",
      "Dates         0\n",
      "Category      0\n",
      "Descript      0\n",
      "DayOfWeek     0\n",
      "PdDistrict    0\n",
      "Resolution    0\n",
      "Address       0\n",
      "X             0\n",
      "Y             0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df = pd.read_csv('sf-crime/train.csv')\n",
    "\n",
    "# A. Data Understanding and Preprocessing\n",
    "\n",
    "# 1. Check the first few rows of the dataset\n",
    "print('First few rows:')\n",
    "print(df.head())\n",
    "\n",
    "# 2. Check for missing values\n",
    "print('Missing values:')\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "md_cleaning",
   "metadata": {},
   "source": [
    "# Data Cleaning\n",
    "- Parse and clean the date column (drop unparseable records)\n",
    "- Remove duplicate rows\n",
    "- Filter out invalid coordinates (keep within San Francisco bounds)\n",
    "- Print dataset shape after cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "975aa7f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (878049, 9)\n",
      "Dates          object\n",
      "Category       object\n",
      "Descript       object\n",
      "DayOfWeek      object\n",
      "PdDistrict     object\n",
      "Resolution     object\n",
      "Address        object\n",
      "X             float64\n",
      "Y             float64\n",
      "dtype: object\n",
      "Duplicate rows: 2323\n",
      "Removed 67 rows outside SF bounds\n",
      "Cleaned shape: (875659, 9)\n"
     ]
    }
   ],
   "source": [
    "# 3. Basic structure and types\n",
    "print('Shape:', df.shape)\n",
    "print(df.dtypes)\n",
    "\n",
    "# 4. Parse date column and handle invalid values\n",
    "date_col = 'Dates' if 'Dates' in df.columns else None\n",
    "if date_col:\n",
    "    df[date_col] = pd.to_datetime(df[date_col], errors='coerce')\n",
    "    invalid_dates = df[date_col].isna().sum()\n",
    "    if invalid_dates:\n",
    "        print(f'Invalid dates: {invalid_dates} — dropping them')\n",
    "        df = df[df[date_col].notna()].copy()\n",
    "else:\n",
    "    print('No date column found')\n",
    "\n",
    "# 5. Drop exact duplicates\n",
    "dup_count = df.duplicated().sum()\n",
    "print('Duplicate rows:', dup_count)\n",
    "if dup_count:\n",
    "    df = df.drop_duplicates().copy()\n",
    "\n",
    "# 6. Sanity check coordinates (keep plausible SF bounds)\n",
    "if {'X','Y'}.issubset(df.columns):\n",
    "    before = len(df)\n",
    "    df = df[df['Y'].between(37.0, 38.0) & df['X'].between(-123.0, -121.0)].copy()\n",
    "    print(f'Removed {before - len(df)} rows outside SF bounds')\n",
    "\n",
    "print('Cleaned shape:', df.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "md_features",
   "metadata": {},
   "source": [
    "# Feature Engineering and Encoding\n",
    "- Construct Arrest_Indicator, Year/Month/Day/Hour, Incident_Quarter\n",
    "- One-hot encode DayOfWeek, PdDistrict, Resolution; label-encode Category if present\n",
    "- Example filters: create subsets by year (e.g., 2015) and district (e.g., Mission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "90d025fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded shape: (875659, 44)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dates</th>\n",
       "      <th>Category</th>\n",
       "      <th>Descript</th>\n",
       "      <th>Address</th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>Arrest_Indicator</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>...</th>\n",
       "      <th>Resolution_JUVENILE CITED</th>\n",
       "      <th>Resolution_JUVENILE DIVERTED</th>\n",
       "      <th>Resolution_LOCATED</th>\n",
       "      <th>Resolution_NONE</th>\n",
       "      <th>Resolution_NOT PROSECUTED</th>\n",
       "      <th>Resolution_PROSECUTED BY OUTSIDE AGENCY</th>\n",
       "      <th>Resolution_PROSECUTED FOR LESSER OFFENSE</th>\n",
       "      <th>Resolution_PSYCHOPATHIC CASE</th>\n",
       "      <th>Resolution_UNFOUNDED</th>\n",
       "      <th>Category_encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-05-13 23:53:00</td>\n",
       "      <td>WARRANTS</td>\n",
       "      <td>WARRANT ARREST</td>\n",
       "      <td>OAK ST / LAGUNA ST</td>\n",
       "      <td>-122.425892</td>\n",
       "      <td>37.774599</td>\n",
       "      <td>1</td>\n",
       "      <td>2015</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-05-13 23:53:00</td>\n",
       "      <td>OTHER OFFENSES</td>\n",
       "      <td>TRAFFIC VIOLATION ARREST</td>\n",
       "      <td>OAK ST / LAGUNA ST</td>\n",
       "      <td>-122.425892</td>\n",
       "      <td>37.774599</td>\n",
       "      <td>1</td>\n",
       "      <td>2015</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-05-13 23:33:00</td>\n",
       "      <td>OTHER OFFENSES</td>\n",
       "      <td>TRAFFIC VIOLATION ARREST</td>\n",
       "      <td>VANNESS AV / GREENWICH ST</td>\n",
       "      <td>-122.424363</td>\n",
       "      <td>37.800414</td>\n",
       "      <td>1</td>\n",
       "      <td>2015</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-05-13 23:30:00</td>\n",
       "      <td>LARCENY/THEFT</td>\n",
       "      <td>GRAND THEFT FROM LOCKED AUTO</td>\n",
       "      <td>1500 Block of LOMBARD ST</td>\n",
       "      <td>-122.426995</td>\n",
       "      <td>37.800873</td>\n",
       "      <td>0</td>\n",
       "      <td>2015</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-05-13 23:30:00</td>\n",
       "      <td>LARCENY/THEFT</td>\n",
       "      <td>GRAND THEFT FROM LOCKED AUTO</td>\n",
       "      <td>100 Block of BRODERICK ST</td>\n",
       "      <td>-122.438738</td>\n",
       "      <td>37.771541</td>\n",
       "      <td>0</td>\n",
       "      <td>2015</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Dates        Category                      Descript  \\\n",
       "0 2015-05-13 23:53:00        WARRANTS                WARRANT ARREST   \n",
       "1 2015-05-13 23:53:00  OTHER OFFENSES      TRAFFIC VIOLATION ARREST   \n",
       "2 2015-05-13 23:33:00  OTHER OFFENSES      TRAFFIC VIOLATION ARREST   \n",
       "3 2015-05-13 23:30:00   LARCENY/THEFT  GRAND THEFT FROM LOCKED AUTO   \n",
       "4 2015-05-13 23:30:00   LARCENY/THEFT  GRAND THEFT FROM LOCKED AUTO   \n",
       "\n",
       "                     Address           X          Y  Arrest_Indicator  Year  \\\n",
       "0         OAK ST / LAGUNA ST -122.425892  37.774599                 1  2015   \n",
       "1         OAK ST / LAGUNA ST -122.425892  37.774599                 1  2015   \n",
       "2  VANNESS AV / GREENWICH ST -122.424363  37.800414                 1  2015   \n",
       "3   1500 Block of LOMBARD ST -122.426995  37.800873                 0  2015   \n",
       "4  100 Block of BRODERICK ST -122.438738  37.771541                 0  2015   \n",
       "\n",
       "   Month  Day  ...  Resolution_JUVENILE CITED Resolution_JUVENILE DIVERTED  \\\n",
       "0      5   13  ...                      False                        False   \n",
       "1      5   13  ...                      False                        False   \n",
       "2      5   13  ...                      False                        False   \n",
       "3      5   13  ...                      False                        False   \n",
       "4      5   13  ...                      False                        False   \n",
       "\n",
       "   Resolution_LOCATED  Resolution_NONE  Resolution_NOT PROSECUTED  \\\n",
       "0               False            False                      False   \n",
       "1               False            False                      False   \n",
       "2               False            False                      False   \n",
       "3               False             True                      False   \n",
       "4               False             True                      False   \n",
       "\n",
       "   Resolution_PROSECUTED BY OUTSIDE AGENCY  \\\n",
       "0                                    False   \n",
       "1                                    False   \n",
       "2                                    False   \n",
       "3                                    False   \n",
       "4                                    False   \n",
       "\n",
       "   Resolution_PROSECUTED FOR LESSER OFFENSE  Resolution_PSYCHOPATHIC CASE  \\\n",
       "0                                     False                         False   \n",
       "1                                     False                         False   \n",
       "2                                     False                         False   \n",
       "3                                     False                         False   \n",
       "4                                     False                         False   \n",
       "\n",
       "   Resolution_UNFOUNDED  Category_encoded  \n",
       "0                 False                37  \n",
       "1                 False                21  \n",
       "2                 False                21  \n",
       "3                 False                16  \n",
       "4                 False                16  \n",
       "\n",
       "[5 rows x 44 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows in 2015: 27522\n",
      "Rows in Mission district: 119722\n"
     ]
    }
   ],
   "source": [
    "# 7. Derived variables: Arrest Indicator, Incident Quarter, calendar parts\n",
    "\n",
    "if 'Resolution' in df.columns:\n",
    "\n",
    "    df['Arrest_Indicator'] = df['Resolution'].str.contains('ARREST', case=False, na=False).astype(int)\n",
    "\n",
    "\n",
    "if 'Dates' in df.columns and pd.api.types.is_datetime64_any_dtype(df['Dates']):\n",
    "\n",
    "    df['Year'] = df['Dates'].dt.year\n",
    "\n",
    "    df['Month'] = df['Dates'].dt.month\n",
    "\n",
    "    df['Day'] = df['Dates'].dt.day\n",
    "\n",
    "    df['Hour'] = df['Dates'].dt.hour\n",
    "\n",
    "    df['Incident_Quarter'] = df['Dates'].dt.to_period('Q').astype(str)\n",
    "\n",
    "\n",
    "# 8. Encode categorical variables (one-hot)\n",
    "\n",
    "categorical_cols = [c for c in ['DayOfWeek','PdDistrict','Resolution'] if c in df.columns]\n",
    "\n",
    "for c in categorical_cols:\n",
    "\n",
    "    df[c] = df[c].astype('category')\n",
    "\n",
    "\n",
    "df_encoded = pd.get_dummies(df, columns=categorical_cols, drop_first=True)\n",
    "\n",
    "\n",
    "# Optionally encode target for modeling later\n",
    "\n",
    "if 'Category' in df_encoded.columns:\n",
    "\n",
    "    le = LabelEncoder()\n",
    "\n",
    "    df_encoded['Category_encoded'] = le.fit_transform(df_encoded['Category'])\n",
    "\n",
    "\n",
    "print('Encoded shape:', df_encoded.shape)\n",
    "\n",
    "display(df_encoded.head())\n",
    "\n",
    "\n",
    "# 9. Optional filter examples (by year and district)\n",
    "\n",
    "if 'Year' in df_encoded.columns:\n",
    "\n",
    "    df_2015 = df_encoded[df_encoded['Year'] == 2015].copy()\n",
    "\n",
    "else:\n",
    "\n",
    "    df_2015 = df_encoded.copy()\n",
    "\n",
    "\n",
    "if 'PdDistrict' in df.columns:\n",
    "\n",
    "    mission_idx = df['PdDistrict'] == 'MISSION'\n",
    "\n",
    "    df_mission = df_encoded[mission_idx].copy()\n",
    "\n",
    "else:\n",
    "\n",
    "    df_mission = df_encoded.copy()\n",
    "\n",
    "\n",
    "print('Rows in 2015:', len(df_2015))\n",
    "\n",
    "print('Rows in Mission district:', len(df_mission))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1cbfde7",
   "metadata": {},
   "source": [
    "# Modeling and Evaluation\n",
    "- Select features and build train/test sets\n",
    "- Compare multiple algorithms (Logistic Regression, Decision Tree, Random Forest; include XGBoost if available)\n",
    "- Use cross-validation with Accuracy and Macro-F1\n",
    "- Report test Accuracy and Macro-F1, and plot the confusion matrix\n",
    "- Perform hyperparameter tuning (GridSearchCV)\n",
    "- Visualize important features and model structure/relationships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4483a0ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected features: 21\n",
      "Sample features: ['X', 'Y', 'Year', 'Month', 'Day', 'Hour', 'DayOfWeek_Monday', 'DayOfWeek_Saturday', 'DayOfWeek_Sunday', 'DayOfWeek_Thursday']\n",
      "Train/Test shapes: (700527, 21) (175132, 21)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 10. Feature selection for modeling the Category\n",
    "# Target\n",
    "if 'Category_encoded' not in df_encoded.columns:\n",
    "    raise ValueError('Target `Category_encoded` not found; ensure earlier cell ran successfully.')\n",
    "\n",
    "y = df_encoded['Category_encoded']\n",
    "\n",
    "# We'll avoid leakage by excluding Resolution-derived columns and Arrest_Indicator.\n",
    "# Also avoid high-cardinality Address_* dummies in features to keep model tractable.\n",
    "# Keep time parts, coordinates, DayOfWeek_*, PdDistrict_*\n",
    "numeric_keep = [c for c in ['Year','Month','Day','Hour','X','Y'] if c in df_encoded.columns]\n",
    "keep_prefixes = ('DayOfWeek_', 'PdDistrict_')\n",
    "\n",
    "X_cols = []\n",
    "for c in df_encoded.columns:\n",
    "    if c in numeric_keep:\n",
    "        X_cols.append(c)\n",
    "    elif c.startswith(keep_prefixes):\n",
    "        X_cols.append(c)\n",
    "\n",
    "# Sanity: Ensure we have features\n",
    "if not X_cols:\n",
    "    raise ValueError('No features selected. Check earlier encoding steps.')\n",
    "\n",
    "X = df_encoded[X_cols].copy()\n",
    "print('Selected features:', len(X_cols))\n",
    "print('Sample features:', X_cols[:10])\n",
    "\n",
    "# Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "print('Train/Test shapes:', X_train.shape, X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c1ef4f",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 28\u001b[39m\n\u001b[32m     26\u001b[39m cv_results = {}\n\u001b[32m     27\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m name, clf \u001b[38;5;129;01min\u001b[39;00m models.items():\n\u001b[32m---> \u001b[39m\u001b[32m28\u001b[39m     res = cross_validate(clf, X, y, cv=cv, scoring=scoring, n_jobs=-\u001b[32m1\u001b[39m, return_train_score=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m     29\u001b[39m     cv_results[name] = {k: (v.mean(), v.std()) \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m res.items() \u001b[38;5;28;01mif\u001b[39;00m k.startswith(\u001b[33m'\u001b[39m\u001b[33mtest_\u001b[39m\u001b[33m'\u001b[39m)}\n\u001b[32m     31\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m'\u001b[39m\u001b[33mCV (5-fold) results:\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/opt/anaconda3/envs/mlproject/lib/python3.13/site-packages/sklearn/utils/_param_validation.py:216\u001b[39m, in \u001b[36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    210\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    211\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m    212\u001b[39m         skip_parameter_validation=(\n\u001b[32m    213\u001b[39m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m    214\u001b[39m         )\n\u001b[32m    215\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m216\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m func(*args, **kwargs)\n\u001b[32m    217\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    218\u001b[39m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[32m    219\u001b[39m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[32m    220\u001b[39m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[32m    221\u001b[39m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[32m    222\u001b[39m     msg = re.sub(\n\u001b[32m    223\u001b[39m         \u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[33m\\\u001b[39m\u001b[33mw+ must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    224\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc.\u001b[34m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    225\u001b[39m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[32m    226\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/opt/anaconda3/envs/mlproject/lib/python3.13/site-packages/sklearn/model_selection/_validation.py:411\u001b[39m, in \u001b[36mcross_validate\u001b[39m\u001b[34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, params, pre_dispatch, return_train_score, return_estimator, return_indices, error_score)\u001b[39m\n\u001b[32m    408\u001b[39m \u001b[38;5;66;03m# We clone the estimator to make sure that all the folds are\u001b[39;00m\n\u001b[32m    409\u001b[39m \u001b[38;5;66;03m# independent, and that it is pickle-able.\u001b[39;00m\n\u001b[32m    410\u001b[39m parallel = Parallel(n_jobs=n_jobs, verbose=verbose, pre_dispatch=pre_dispatch)\n\u001b[32m--> \u001b[39m\u001b[32m411\u001b[39m results = parallel(\n\u001b[32m    412\u001b[39m     delayed(_fit_and_score)(\n\u001b[32m    413\u001b[39m         clone(estimator),\n\u001b[32m    414\u001b[39m         X,\n\u001b[32m    415\u001b[39m         y,\n\u001b[32m    416\u001b[39m         scorer=scorers,\n\u001b[32m    417\u001b[39m         train=train,\n\u001b[32m    418\u001b[39m         test=test,\n\u001b[32m    419\u001b[39m         verbose=verbose,\n\u001b[32m    420\u001b[39m         parameters=\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    421\u001b[39m         fit_params=routed_params.estimator.fit,\n\u001b[32m    422\u001b[39m         score_params=routed_params.scorer.score,\n\u001b[32m    423\u001b[39m         return_train_score=return_train_score,\n\u001b[32m    424\u001b[39m         return_times=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m    425\u001b[39m         return_estimator=return_estimator,\n\u001b[32m    426\u001b[39m         error_score=error_score,\n\u001b[32m    427\u001b[39m     )\n\u001b[32m    428\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m train, test \u001b[38;5;129;01min\u001b[39;00m indices\n\u001b[32m    429\u001b[39m )\n\u001b[32m    431\u001b[39m _warn_or_raise_about_fit_failures(results, error_score)\n\u001b[32m    433\u001b[39m \u001b[38;5;66;03m# For callable scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[32m    434\u001b[39m \u001b[38;5;66;03m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[32m    435\u001b[39m \u001b[38;5;66;03m# the correct key.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/opt/anaconda3/envs/mlproject/lib/python3.13/site-packages/sklearn/utils/parallel.py:77\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m     72\u001b[39m config = get_config()\n\u001b[32m     73\u001b[39m iterable_with_config = (\n\u001b[32m     74\u001b[39m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[32m     75\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[32m     76\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m77\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m().\u001b[34m__call__\u001b[39m(iterable_with_config)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/opt/anaconda3/envs/mlproject/lib/python3.13/site-packages/joblib/parallel.py:2071\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   2065\u001b[39m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[32m   2066\u001b[39m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[32m   2067\u001b[39m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[32m   2068\u001b[39m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[32m   2069\u001b[39m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[32m-> \u001b[39m\u001b[32m2071\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(output)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/opt/anaconda3/envs/mlproject/lib/python3.13/site-packages/joblib/parallel.py:1681\u001b[39m, in \u001b[36mParallel._get_outputs\u001b[39m\u001b[34m(self, iterator, pre_dispatch)\u001b[39m\n\u001b[32m   1678\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[32m   1680\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backend.retrieval_context():\n\u001b[32m-> \u001b[39m\u001b[32m1681\u001b[39m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m._retrieve()\n\u001b[32m   1683\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[32m   1684\u001b[39m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[32m   1685\u001b[39m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[32m   1686\u001b[39m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[32m   1687\u001b[39m     \u001b[38;5;28mself\u001b[39m._exception = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/opt/anaconda3/envs/mlproject/lib/python3.13/site-packages/joblib/parallel.py:1799\u001b[39m, in \u001b[36mParallel._retrieve\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1788\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_ordered:\n\u001b[32m   1789\u001b[39m     \u001b[38;5;66;03m# Case ordered: wait for completion (or error) of the next job\u001b[39;00m\n\u001b[32m   1790\u001b[39m     \u001b[38;5;66;03m# that have been dispatched and not retrieved yet. If no job\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1794\u001b[39m     \u001b[38;5;66;03m# control only have to be done on the amount of time the next\u001b[39;00m\n\u001b[32m   1795\u001b[39m     \u001b[38;5;66;03m# dispatched job is pending.\u001b[39;00m\n\u001b[32m   1796\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m (nb_jobs == \u001b[32m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   1797\u001b[39m         \u001b[38;5;28mself\u001b[39m._jobs[\u001b[32m0\u001b[39m].get_status(timeout=\u001b[38;5;28mself\u001b[39m.timeout) == TASK_PENDING\n\u001b[32m   1798\u001b[39m     ):\n\u001b[32m-> \u001b[39m\u001b[32m1799\u001b[39m         time.sleep(\u001b[32m0.01\u001b[39m)\n\u001b[32m   1800\u001b[39m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m   1802\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m nb_jobs == \u001b[32m0\u001b[39m:\n\u001b[32m   1803\u001b[39m     \u001b[38;5;66;03m# Case unordered: jobs are added to the list of jobs to\u001b[39;00m\n\u001b[32m   1804\u001b[39m     \u001b[38;5;66;03m# retrieve `self._jobs` only once completed or in error, which\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1810\u001b[39m     \u001b[38;5;66;03m# timeouts before any other dispatched job has completed and\u001b[39;00m\n\u001b[32m   1811\u001b[39m     \u001b[38;5;66;03m# been added to `self._jobs` to be retrieved.\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "\n",
    "# 11. Cross-validation comparison of baseline models\n",
    "\n",
    "models = {\n",
    "    'Logistic': LogisticRegression(max_iter=1000, n_jobs=None),\n",
    "    'DecisionTree': DecisionTreeClassifier(random_state=42),\n",
    "    'RandomForest': RandomForestClassifier(n_estimators=200, random_state=42, n_jobs=-1)\n",
    "}\n",
    "\n",
    "# Optionally include XGBoost if available\n",
    "try:\n",
    "    models['XGBoost'] = XGBClassifier(\n",
    "        n_estimators=200, learning_rate=0.1, max_depth=6, subsample=0.8, colsample_bytree=0.8,\n",
    "        objective='multi:softprob', eval_metric='mlogloss', n_jobs=-1, random_state=42\n",
    "    )\n",
    "except Exception as e:\n",
    "    print('XGBoost not available, skipping.')\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "scoring = {'acc':'accuracy','f1_macro':'f1_macro'}\n",
    "\n",
    "cv_results = {}\n",
    "for name, clf in models.items():\n",
    "    res = cross_validate(clf, X, y, cv=cv, scoring=scoring, n_jobs=-1, return_train_score=False)\n",
    "    cv_results[name] = {k: (v.mean(), v.std()) for k, v in res.items() if k.startswith('test_')}\n",
    "\n",
    "print('CV (5-fold) results:')\n",
    "for name, res in cv_results.items():\n",
    "    print(f\"{name:12s} | Acc: {res['test_acc'][0]:.3f} ± {res['test_acc'][1]:.3f} | F1_macro: {res['test_f1_macro'][0]:.3f} ± {res['test_f1_macro'][1]:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc5869a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 12. Train/test evaluation and confusion matrix\n",
    "\n",
    "fit_results = {}\n",
    "for name, clf in models.items():\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    f1m = f1_score(y_test, y_pred, average='macro')\n",
    "    fit_results[name] = {'acc': acc, 'f1_macro': f1m, 'y_pred': y_pred}\n",
    "    print(f\"{name} -> Test Accuracy: {acc:.3f}, Macro-F1: {f1m:.3f}\")\n",
    "\n",
    "# Pick best by Macro-F1\n",
    "best_name = max(fit_results, key=lambda k: fit_results[k]['f1_macro'])\n",
    "print(f\"Best (by Macro-F1): {best_name}\")\n",
    "\n",
    "y_pred_best = fit_results[best_name]['y_pred']\n",
    "cm = confusion_matrix(y_test, y_pred_best)\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(cm, cmap='Blues', cbar=False)\n",
    "plt.title(f'Confusion Matrix — {best_name}')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print('Classification report for best model:')\n",
    "print(classification_report(y_test, y_pred_best))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "115105d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 13. Hyperparameter tuning (GridSearchCV)\n",
    "\n",
    "search_spaces = {\n",
    "    'Logistic': (LogisticRegression(max_iter=1000),\n",
    "                 {'C':[0.1,1,3], 'penalty':['l2'], 'solver':['lbfgs'] }),\n",
    "    'DecisionTree': (DecisionTreeClassifier(random_state=42),\n",
    "                     {'max_depth':[None,10,20], 'min_samples_split':[2,10,50]}),\n",
    "    'RandomForest': (RandomForestClassifier(random_state=42, n_jobs=-1),\n",
    "                     {'n_estimators':[200,400], 'max_depth':[None,20], 'min_samples_split':[2,10]})\n",
    "}\n",
    "\n",
    "best_estimators = {}\n",
    "for name, (est, grid) in search_spaces.items():\n",
    "    print(f\"Tuning {name} ...\")\n",
    "    gs = GridSearchCV(est, grid, cv=3, scoring='f1_macro', n_jobs=-1, verbose=0)\n",
    "    gs.fit(X_train, y_train)\n",
    "    print('Best params:', gs.best_params_)\n",
    "    print('Best CV f1_macro:', gs.best_score_)\n",
    "    best_estimators[name] = gs.best_estimator_\n",
    "\n",
    "# Evaluate tuned models\n",
    "for name, est in best_estimators.items():\n",
    "    y_pred = est.predict(X_test)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    f1m = f1_score(y_test, y_pred, average='macro')\n",
    "    print(f\"{name} (tuned) -> Test Accuracy: {acc:.3f}, Macro-F1: {f1m:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aafea9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 14. Visualizations: feature importance and tree structure (if applicable)\n",
    "\n",
    "# Feature importances for RandomForest (tuned if available)\n",
    "rf = best_estimators.get('RandomForest', models.get('RandomForest'))\n",
    "if hasattr(rf, 'feature_importances_'):\n",
    "    importances = rf.feature_importances_\n",
    "    idx = np.argsort(importances)[::-1][:15]\n",
    "    plt.figure(figsize=(8,5))\n",
    "    plt.barh(range(len(idx)), importances[idx][::-1])\n",
    "    plt.yticks(range(len(idx)), [X.columns[i] for i in idx][::-1])\n",
    "    plt.title('Top 15 Feature Importances — RandomForest')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Plot a shallow Decision Tree for interpretability\n",
    "clf_tree = best_estimators.get('DecisionTree', DecisionTreeClassifier(max_depth=3, random_state=42))\n",
    "if not hasattr(clf_tree, 'tree_'):\n",
    "    clf_tree.fit(X_train, y_train)\n",
    "plt.figure(figsize=(12,6))\n",
    "plot_tree(clf_tree, feature_names=X.columns.tolist(), max_depth=3, filled=True, fontsize=6)\n",
    "plt.title('Decision Tree (depth<=3)')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
